{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01.00 Basic random forest\n",
    "\n",
    "* This model only uses sequences to make prediction.\n",
    "* This model uses random forest mode of LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import lzma\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', 'The least populated class')\n",
    "warnings.filterwarnings('ignore', 'categorical_feature in Dataset is overridden')\n",
    "warnings.filterwarnings('ignore', 'object name is not a valid Python identifier')\n",
    "\n",
    "import hyperopt\n",
    "import lightgbm\n",
    "import numpy\n",
    "import pandas\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import tables\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materials\n",
    "\n",
    "* Training sequences, their fitness values, and the numbers of mutations (for stratified cross-validation).\n",
    "* Validation sequences and their fitness values for evaluation, results of which are kept secret for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = utils.data.load_sequence('training', one_hot=False)\n",
    "y = utils.data.load('training', 'fitness')\n",
    "mutation_count = utils.data.load('training', 'mutation_count')\n",
    "fitness_group = utils.data.load('training', 'fitness_group')\n",
    "groups = mutation_count * (fitness_group.max() + 1) + fitness_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_x = utils.data.load_sequence('validation', one_hot=False)\n",
    "validation_y = utils.data.average_fitness(utils.data.load('validation', 'fitness'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "* Search for the best hyperparameters for the LightGBM model.\n",
    "* Retrain the LightGBM model with the best hyperparameters over the pre-defined cross-validation splits, and score them.\n",
    "* Retrain the LightGBM model over the pre-defined stacking splits, and predict the folds.\n",
    "* Retrain the LightGBM model over the whole training set, predict the leaderboard set, and score it.\n",
    "* Keep leaderboard scores secret for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def search_models(arguments):\n",
    "    kfold = sklearn.model_selection.RepeatedStratifiedKFold(n_splits=2, n_repeats=5)\n",
    "    score = []\n",
    "    parameters = copy.deepcopy(arguments)\n",
    "    parameters['num_leaves'] = int(parameters['num_leaves'])\n",
    "    parameters['n_estimators'] = int(parameters['n_estimators'])\n",
    "    for train_idx, test_idx in kfold.split(x, groups):\n",
    "        model = lightgbm.LGBMRegressor(boosting_type='rf', subsample_freq=1, **parameters)\n",
    "        train_x = numpy.repeat(x[train_idx, :], utils.data.REPLICA_COUNT, axis=0)\n",
    "        train_y = y[train_idx, :].flatten()\n",
    "        model.fit(train_x, train_y, categorical_feature=list(range(utils.data.SEQUENCE_LENGTH)))\n",
    "        test_x = x[test_idx, :]\n",
    "        prediction = model.predict(test_x)\n",
    "        test_y = utils.data.average_fitness(y[test_idx, :])\n",
    "        score.append(utils.metrics.minimization_metric(test_y, prediction))\n",
    "    score = sum(score) / len(score)\n",
    "    return score\n",
    "\n",
    "\n",
    "parameter_space = {\n",
    "    'num_leaves': 2 ** hyperopt.hp.quniform('num_leaves', 4, 12, 2) - 1,\n",
    "    'n_estimators': 2 ** hyperopt.hp.quniform('n_estimators', 0, 4, 1) * 50,\n",
    "    'colsample_bytree': hyperopt.hp.quniform('colsample_bytree', 0.1, 0.9, 0.1),\n",
    "    'subsample': hyperopt.hp.quniform('subsample', 0, 0.8, 0.2) + 0.1,\n",
    "}\n",
    "try:\n",
    "    trials = pickle.load((utils.data.path(2) / '00.hyperopt_trials.pickle').open('rb'))\n",
    "except:\n",
    "    trials = hyperopt.Trials()\n",
    "try:\n",
    "    hyperopt.fmin(search_models, space=parameter_space, trials=trials,\n",
    "                         algo=hyperopt.tpe.suggest, max_evals=100)\n",
    "finally:\n",
    "    trials.refresh()\n",
    "    pickle.dump(trials, (utils.data.path(2) / '00.hyperopt_trials.pickle').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = pickle.load(open('../../data/02.LightGBM_models/00.hyperopt_trials.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Recover the parameters back to their correct scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = trials.argmin\n",
    "parameters = copy.deepcopy(best)\n",
    "parameters['num_leaves'] = int(2 ** parameters['num_leaves'] - 1)\n",
    "parameters['n_estimators'] = int(2 ** parameters['n_estimators'] * 50)\n",
    "parameters['subsample'] = parameters['subsample'] + 0.1\n",
    "model_file = tables.open_file(utils.data.path(2) / '00.model.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/cv_scores (Table(10,)) ''\n",
       "  description := {\n",
       "  \"Pearson\": Float64Col(shape=(), dflt=0.0, pos=0),\n",
       "  \"Log-pearson\": Float64Col(shape=(), dflt=0.0, pos=1),\n",
       "  \"Spearman\": Float64Col(shape=(), dflt=0.0, pos=2),\n",
       "  \"Kendall\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"MSE\": Float64Col(shape=(), dflt=0.0, pos=4),\n",
       "  \"Log-MSE\": Float64Col(shape=(), dflt=0.0, pos=5),\n",
       "  \"AUC 0.5\": Float64Col(shape=(), dflt=0.0, pos=6),\n",
       "  \"AUC 1\": Float64Col(shape=(), dflt=0.0, pos=7)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (1024,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for train_idx in utils.data.predefined_cross_validation():\n",
    "    test_idx = ~train_idx\n",
    "    model = lightgbm.LGBMRegressor(boosting_type='rf', subsample_freq=1, **parameters)\n",
    "    train_x = numpy.repeat(x[train_idx, :], utils.data.REPLICA_COUNT, axis=0)\n",
    "    train_y = y[train_idx, :].flatten()\n",
    "    model.fit(train_x, train_y, categorical_feature=list(range(utils.data.SEQUENCE_LENGTH)))\n",
    "    test_x = x[test_idx, :]\n",
    "    prediction = model.predict(test_x).clip(min=1e-7)\n",
    "    test_y = utils.data.average_fitness(y[test_idx, :])\n",
    "    scores.append(utils.metrics.evaluation_metrics(test_y, prediction))\n",
    "scores = pandas.concat(scores, axis=1).T\n",
    "model_file.create_table('/', 'cv_scores', obj=scores.to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/stack_samples (Array(49153,)) ''\n",
       "  atom := Float32Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = numpy.ndarray(y.shape[0], dtype='f4')\n",
    "prediction[:] = float('nan')\n",
    "for train_idx in utils.data.stacking_splits():\n",
    "    test_idx = ~train_idx\n",
    "    model = lightgbm.LGBMRegressor(boosting_type='rf', subsample_freq=1, **parameters)\n",
    "    train_x = numpy.repeat(x[train_idx, :], utils.data.REPLICA_COUNT, axis=0)\n",
    "    train_y = y[train_idx, :].flatten()\n",
    "    model.fit(train_x, train_y, categorical_feature=list(range(utils.data.SEQUENCE_LENGTH)))\n",
    "    test_x = x[test_idx, :]\n",
    "    prediction[test_idx] = model.predict(test_x).clip(min=1e-7)\n",
    "model_file.create_array('/', 'stack_samples', obj=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/validation_score (Table(1,)) ''\n",
       "  description := {\n",
       "  \"Pearson\": Float64Col(shape=(), dflt=0.0, pos=0),\n",
       "  \"Log-pearson\": Float64Col(shape=(), dflt=0.0, pos=1),\n",
       "  \"Spearman\": Float64Col(shape=(), dflt=0.0, pos=2),\n",
       "  \"Kendall\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"MSE\": Float64Col(shape=(), dflt=0.0, pos=4),\n",
       "  \"Log-MSE\": Float64Col(shape=(), dflt=0.0, pos=5),\n",
       "  \"AUC 0.5\": Float64Col(shape=(), dflt=0.0, pos=6),\n",
       "  \"AUC 1\": Float64Col(shape=(), dflt=0.0, pos=7)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (1024,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = numpy.ndarray(y.shape[0], dtype='f4')\n",
    "model = lightgbm.LGBMRegressor(boosting_type='rf', subsample_freq=1, **parameters)\n",
    "full_x = numpy.repeat(x, utils.data.REPLICA_COUNT, axis=0)\n",
    "model.fit(full_x, y.flatten(), categorical_feature=list(range(utils.data.SEQUENCE_LENGTH)))\n",
    "with lzma.LZMAFile(utils.data.path(2) / '00.training_model.pickle.xz', 'w') as xz:\n",
    "    pickle.dump(model, xz)\n",
    "prediction = model.predict(validation_x).clip(min=1e-7)\n",
    "model_file.create_array('/', 'validation_samples', obj=prediction)\n",
    "score = utils.metrics.evaluation_metrics(validation_y, prediction)\n",
    "score = pandas.DataFrame(score).T\n",
    "model_file.create_table('/', 'validation_score', obj=score.to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'n_estimators': 4.0,\n",
       " 'num_leaves': 12.0,\n",
       " 'subsample': 0.4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'state': 2,\n",
       "  'tid': 80,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4250860758556471, 'status': 'ok'},\n",
       "  'misc': {'tid': 80,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [80],\n",
       "    'n_estimators': [80],\n",
       "    'num_leaves': [80],\n",
       "    'subsample': [80]},\n",
       "   'vals': {'colsample_bytree': [0.5],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 9, 34, 2, 208000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 9, 44, 55, 378000)},\n",
       " {'state': 2,\n",
       "  'tid': 78,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4247629728504327, 'status': 'ok'},\n",
       "  'misc': {'tid': 78,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [78],\n",
       "    'n_estimators': [78],\n",
       "    'num_leaves': [78],\n",
       "    'subsample': [78]},\n",
       "   'vals': {'colsample_bytree': [0.5],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 9, 10, 45, 999000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 9, 21, 34, 666000)},\n",
       " {'state': 2,\n",
       "  'tid': 91,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4246298253842598, 'status': 'ok'},\n",
       "  'misc': {'tid': 91,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [91],\n",
       "    'n_estimators': [91],\n",
       "    'num_leaves': [91],\n",
       "    'subsample': [91]},\n",
       "   'vals': {'colsample_bytree': [0.5],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 10, 47, 50, 512000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 10, 59, 0, 528000)},\n",
       " {'state': 2,\n",
       "  'tid': 96,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4246118947595029, 'status': 'ok'},\n",
       "  'misc': {'tid': 96,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [96],\n",
       "    'n_estimators': [96],\n",
       "    'num_leaves': [96],\n",
       "    'subsample': [96]},\n",
       "   'vals': {'colsample_bytree': [0.5],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [10.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 11, 21, 40, 384000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 11, 31, 22, 588000)},\n",
       " {'state': 2,\n",
       "  'tid': 86,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.42449893020911916, 'status': 'ok'},\n",
       "  'misc': {'tid': 86,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [86],\n",
       "    'n_estimators': [86],\n",
       "    'num_leaves': [86],\n",
       "    'subsample': [86]},\n",
       "   'vals': {'colsample_bytree': [0.5],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 10, 17, 46, 639000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 10, 28, 46, 592000)},\n",
       " {'state': 2,\n",
       "  'tid': 68,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4237217736151136, 'status': 'ok'},\n",
       "  'misc': {'tid': 68,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [68],\n",
       "    'n_estimators': [68],\n",
       "    'num_leaves': [68],\n",
       "    'subsample': [68]},\n",
       "   'vals': {'colsample_bytree': [0.4],\n",
       "    'n_estimators': [3.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 8, 48, 49, 738000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 8, 53, 0, 822000)},\n",
       " {'state': 2,\n",
       "  'tid': 67,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4236246258142208, 'status': 'ok'},\n",
       "  'misc': {'tid': 67,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [67],\n",
       "    'n_estimators': [67],\n",
       "    'num_leaves': [67],\n",
       "    'subsample': [67]},\n",
       "   'vals': {'colsample_bytree': [0.4],\n",
       "    'n_estimators': [3.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 8, 44, 38, 375000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 8, 48, 49, 691000)},\n",
       " {'state': 2,\n",
       "  'tid': 79,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.42332749304206485, 'status': 'ok'},\n",
       "  'misc': {'tid': 79,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [79],\n",
       "    'n_estimators': [79],\n",
       "    'num_leaves': [79],\n",
       "    'subsample': [79]},\n",
       "   'vals': {'colsample_bytree': [0.6000000000000001],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 9, 21, 34, 717000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 9, 34, 2, 159000)},\n",
       " {'state': 2,\n",
       "  'tid': 92,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4231446579666732, 'status': 'ok'},\n",
       "  'misc': {'tid': 92,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [92],\n",
       "    'n_estimators': [92],\n",
       "    'num_leaves': [92],\n",
       "    'subsample': [92]},\n",
       "   'vals': {'colsample_bytree': [0.6000000000000001],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [10.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 10, 59, 0, 584000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 11, 8, 58, 960000)},\n",
       " {'state': 2,\n",
       "  'tid': 61,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4230825778872876, 'status': 'ok'},\n",
       "  'misc': {'tid': 61,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [61],\n",
       "    'n_estimators': [61],\n",
       "    'num_leaves': [61],\n",
       "    'subsample': [61]},\n",
       "   'vals': {'colsample_bytree': [0.4],\n",
       "    'n_estimators': [3.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.6000000000000001]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 8, 18, 0, 214000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 8, 22, 35, 827000)},\n",
       " {'state': 2,\n",
       "  'tid': 85,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.42289335884374113, 'status': 'ok'},\n",
       "  'misc': {'tid': 85,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [85],\n",
       "    'n_estimators': [85],\n",
       "    'num_leaves': [85],\n",
       "    'subsample': [85]},\n",
       "   'vals': {'colsample_bytree': [0.6000000000000001],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [10.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 10, 7, 54, 630000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 10, 17, 46, 586000)},\n",
       " {'state': 2,\n",
       "  'tid': 66,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.42270198463197073, 'status': 'ok'},\n",
       "  'misc': {'tid': 66,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [66],\n",
       "    'n_estimators': [66],\n",
       "    'num_leaves': [66],\n",
       "    'subsample': [66]},\n",
       "   'vals': {'colsample_bytree': [0.4],\n",
       "    'n_estimators': [3.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.6000000000000001]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 8, 40, 3, 103000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 8, 44, 38, 329000)},\n",
       " {'state': 2,\n",
       "  'tid': 5,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4225917000155202, 'status': 'ok'},\n",
       "  'misc': {'tid': 5,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [5],\n",
       "    'n_estimators': [5],\n",
       "    'num_leaves': [5],\n",
       "    'subsample': [5]},\n",
       "   'vals': {'colsample_bytree': [0.5],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [10.0],\n",
       "    'subsample': [0.8]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 4, 46, 7, 109000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 4, 54, 34, 673000)},\n",
       " {'state': 2,\n",
       "  'tid': 32,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4225648454437151, 'status': 'ok'},\n",
       "  'misc': {'tid': 32,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [32],\n",
       "    'n_estimators': [32],\n",
       "    'num_leaves': [32],\n",
       "    'subsample': [32]},\n",
       "   'vals': {'colsample_bytree': [0.4],\n",
       "    'n_estimators': [3.0],\n",
       "    'num_leaves': [10.0],\n",
       "    'subsample': [0.6000000000000001]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 6, 41, 47, 866000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 6, 45, 41, 18000)},\n",
       " {'state': 2,\n",
       "  'tid': 38,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.42247428669245535, 'status': 'ok'},\n",
       "  'misc': {'tid': 38,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [38],\n",
       "    'n_estimators': [38],\n",
       "    'num_leaves': [38],\n",
       "    'subsample': [38]},\n",
       "   'vals': {'colsample_bytree': [0.5],\n",
       "    'n_estimators': [3.0],\n",
       "    'num_leaves': [10.0],\n",
       "    'subsample': [0.8]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 6, 57, 50, 793000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 7, 1, 55, 272000)},\n",
       " {'state': 2,\n",
       "  'tid': 42,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.42243089214074014, 'status': 'ok'},\n",
       "  'misc': {'tid': 42,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [42],\n",
       "    'n_estimators': [42],\n",
       "    'num_leaves': [42],\n",
       "    'subsample': [42]},\n",
       "   'vals': {'colsample_bytree': [0.4],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [10.0],\n",
       "    'subsample': [0.6000000000000001]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 7, 15, 38, 995000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 7, 23, 40, 116000)},\n",
       " {'state': 2,\n",
       "  'tid': 25,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.42225790392117657, 'status': 'ok'},\n",
       "  'misc': {'tid': 25,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [25],\n",
       "    'n_estimators': [25],\n",
       "    'num_leaves': [25],\n",
       "    'subsample': [25]},\n",
       "   'vals': {'colsample_bytree': [0.6000000000000001],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [10.0],\n",
       "    'subsample': [0.6000000000000001]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 5, 43, 57, 201000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 5, 52, 49, 632000)},\n",
       " {'state': 2,\n",
       "  'tid': 82,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.42225770697116716, 'status': 'ok'},\n",
       "  'misc': {'tid': 82,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [82],\n",
       "    'n_estimators': [82],\n",
       "    'num_leaves': [82],\n",
       "    'subsample': [82]},\n",
       "   'vals': {'colsample_bytree': [0.6000000000000001],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [10.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 9, 47, 8, 870000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 9, 57, 1, 749000)},\n",
       " {'state': 2,\n",
       "  'tid': 58,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.422031827766577, 'status': 'ok'},\n",
       "  'misc': {'tid': 58,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [58],\n",
       "    'n_estimators': [58],\n",
       "    'num_leaves': [58],\n",
       "    'subsample': [58]},\n",
       "   'vals': {'colsample_bytree': [0.30000000000000004],\n",
       "    'n_estimators': [4.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.4]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 8, 8, 54, 625000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 8, 15, 4, 63000)},\n",
       " {'state': 2,\n",
       "  'tid': 41,\n",
       "  'spec': None,\n",
       "  'result': {'loss': -0.4219209802895527, 'status': 'ok'},\n",
       "  'misc': {'tid': 41,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'colsample_bytree': [41],\n",
       "    'n_estimators': [41],\n",
       "    'num_leaves': [41],\n",
       "    'subsample': [41]},\n",
       "   'vals': {'colsample_bytree': [0.5],\n",
       "    'n_estimators': [3.0],\n",
       "    'num_leaves': [12.0],\n",
       "    'subsample': [0.8]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2018, 12, 28, 7, 8, 28, 160000),\n",
       "  'refresh_time': datetime.datetime(2018, 12, 28, 7, 15, 38, 959000)}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(trials.trials, key=lambda x: x['result']['loss'])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Log-pearson</th>\n",
       "      <th>Spearman</th>\n",
       "      <th>Kendall</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Log-MSE</th>\n",
       "      <th>AUC 0.5</th>\n",
       "      <th>AUC 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.634268</td>\n",
       "      <td>0.638934</td>\n",
       "      <td>0.562720</td>\n",
       "      <td>0.426156</td>\n",
       "      <td>0.011760</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.759271</td>\n",
       "      <td>0.937929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.637521</td>\n",
       "      <td>0.641324</td>\n",
       "      <td>0.559988</td>\n",
       "      <td>0.424735</td>\n",
       "      <td>0.011714</td>\n",
       "      <td>0.024707</td>\n",
       "      <td>0.756715</td>\n",
       "      <td>0.949671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.629420</td>\n",
       "      <td>0.633688</td>\n",
       "      <td>0.555587</td>\n",
       "      <td>0.420523</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>0.755384</td>\n",
       "      <td>0.940757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.643429</td>\n",
       "      <td>0.647255</td>\n",
       "      <td>0.567964</td>\n",
       "      <td>0.430983</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>0.024802</td>\n",
       "      <td>0.761624</td>\n",
       "      <td>0.944131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.642173</td>\n",
       "      <td>0.646228</td>\n",
       "      <td>0.565098</td>\n",
       "      <td>0.429015</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>0.025001</td>\n",
       "      <td>0.759754</td>\n",
       "      <td>0.942369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.633743</td>\n",
       "      <td>0.637582</td>\n",
       "      <td>0.558038</td>\n",
       "      <td>0.422306</td>\n",
       "      <td>0.011525</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>0.756336</td>\n",
       "      <td>0.946079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.636250</td>\n",
       "      <td>0.640027</td>\n",
       "      <td>0.560683</td>\n",
       "      <td>0.424816</td>\n",
       "      <td>0.011692</td>\n",
       "      <td>0.024661</td>\n",
       "      <td>0.757988</td>\n",
       "      <td>0.945593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.641913</td>\n",
       "      <td>0.645595</td>\n",
       "      <td>0.563116</td>\n",
       "      <td>0.426933</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.024737</td>\n",
       "      <td>0.758744</td>\n",
       "      <td>0.943348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.636748</td>\n",
       "      <td>0.641418</td>\n",
       "      <td>0.564254</td>\n",
       "      <td>0.427457</td>\n",
       "      <td>0.011868</td>\n",
       "      <td>0.024949</td>\n",
       "      <td>0.759133</td>\n",
       "      <td>0.938265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.639417</td>\n",
       "      <td>0.642471</td>\n",
       "      <td>0.558992</td>\n",
       "      <td>0.423972</td>\n",
       "      <td>0.011567</td>\n",
       "      <td>0.024470</td>\n",
       "      <td>0.757250</td>\n",
       "      <td>0.950161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.637488</td>\n",
       "      <td>0.641452</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.425689</td>\n",
       "      <td>0.011725</td>\n",
       "      <td>0.024722</td>\n",
       "      <td>0.758220</td>\n",
       "      <td>0.943830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>0.004373</td>\n",
       "      <td>0.004194</td>\n",
       "      <td>0.003688</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.004217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pearson  Log-pearson  Spearman   Kendall       MSE   Log-MSE   AUC 0.5  \\\n",
       "0     0.634268     0.638934  0.562720  0.426156  0.011760  0.024777  0.759271   \n",
       "1     0.637521     0.641324  0.559988  0.424735  0.011714  0.024707  0.756715   \n",
       "2     0.629420     0.633688  0.555587  0.420523  0.011681  0.024682  0.755384   \n",
       "3     0.643429     0.647255  0.567964  0.430983  0.011789  0.024802  0.761624   \n",
       "4     0.642173     0.646228  0.565098  0.429015  0.011919  0.025001  0.759754   \n",
       "5     0.633743     0.637582  0.558038  0.422306  0.011525  0.024437  0.756336   \n",
       "6     0.636250     0.640027  0.560683  0.424816  0.011692  0.024661  0.757988   \n",
       "7     0.641913     0.645595  0.563116  0.426933  0.011735  0.024737  0.758744   \n",
       "8     0.636748     0.641418  0.564254  0.427457  0.011868  0.024949  0.759133   \n",
       "9     0.639417     0.642471  0.558992  0.423972  0.011567  0.024470  0.757250   \n",
       "Mean  0.637488     0.641452  0.561644  0.425689  0.011725  0.024722  0.758220   \n",
       "Std   0.004373     0.004194  0.003688  0.003104  0.000121  0.000179  0.001856   \n",
       "\n",
       "         AUC 1  \n",
       "0     0.937929  \n",
       "1     0.949671  \n",
       "2     0.940757  \n",
       "3     0.944131  \n",
       "4     0.942369  \n",
       "5     0.946079  \n",
       "6     0.945593  \n",
       "7     0.943348  \n",
       "8     0.938265  \n",
       "9     0.950161  \n",
       "Mean  0.943830  \n",
       "Std   0.004217  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = pandas.DataFrame(scores.mean()).T\n",
    "mean.index = ['Mean']\n",
    "std = pandas.DataFrame(scores.std()).T\n",
    "std.index = ['Std']\n",
    "pandas.concat([scores, mean, std], axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
